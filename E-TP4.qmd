# TP4 : Probabilités et Statistiques avec R

```{r global-options, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, eval=FALSE)

library(tidyverse)

```

## 1. Probabilités avec R

### 1.1 - Échantillonnage

Vous êtes la fée des loteries dans une loterie hebdomadaire, où 6 numéros uniques sur 49 sont tirés.

1.  Tirez aléatoirement les numéros gagnants de cette semaine (fixez la graine à 123) en utilisant la fonction `sample`.

```{r Solution 1.1, eval=F}
set.seed(123)

sample(seq(49),6) # ou sample(49,6)



```

### 1.2 - Fonction de densité de probabilité

Considérez une variable aléatoire $X$ avec une fonction de densité de probabilité (PDF)

$$f_X(x)=\frac{x}{4}e^{-x^2/8},\quad x\geq 0.$$

1.  Définissez la PDF ci-dessus comme une fonction $f()$.

2.  Vérifiez si la fonction que vous avez définie est effectivement une PDF.

```{r Solution 1.2, eval=F}
#1
f <- function(x){x/4*exp(-x^2/8)}

#2
integrate(f, 0, Inf)$value


curve(f, xlim = c(0,25))

```

### 1.3 - Espérance et Variance

Dans cet exercice, vous devez calculer l'espérance et la variance de la variable aléatoire $X$ considérée dans l'exercice précédent.

La PDF $f()$ de l'exercice précédent est disponible dans votre environnement de travail.

1.  Définissez une fonction appropriée `ex()` qui s'intègre à l'espérance de $X$.
2.  Calculez l'espérance de $X$. Stockez le résultat dans `expected_value`.
3.  Définissez une fonction appropriée `ex2()` qui s'intègre à l'espérance de $X^2$.
4.  Calculez la variance de $X$. Stockez le résultat dans `variance`.

```{r Solution 1.3, eval=F}
set.seed(123)
#1. 
qnorm(0.99, mean = 5, sd = sqrt(25))
#2
rnorm(10, mean = 2, sd = sqrt(12))
```

```{r Solution 3, eval=F}
#1
ex <- function(x){x*f(x)}



#2
expected_value <- integrate(ex, 0, Inf)$value

#3
ex2 <- function(x){x**2*f(x)}

#4
variance <- integrate(ex2, 0, Inf)$value - expected_value**2


```

## 4 - Distribution Normale Standard

Soit \$Z\\sim \\mathcal{N}(0, 1)\$.

1.  Calculez \$\\phi(3)\$, c'est-à-dire la valeur de la densité de probabilité standard normale en \$c=3\$.
2.  Calculez \$P(\|Z\|\\leq 1.64)\$ en utilisant la fonction \`pnorm()\`.

### 1.4 - Distribution du Chi-carré

1.  Soit $W\sim \chi^2_{1,0}$. Tracez la PDF correspondante à l'aide de `curve()`. Spécifiez la plage de valeurs $x$ comme [0,25] via l'argument `xlim.`
2.  Soient $X_1$ et $X_2$ deux variables aléatoires normalement distribuées indépendantes avec $\mu=0$ et $\sigma^2=15$. Calculez $P(X_1^2+X_2^2>10)$

```{r Solution 1.4, eval=F}
#1 
curve(dchisq(x, df = 2), xlim = c(0, 25))
#2


pchisq(10/15, df = 2, lower.tail = F)
1 - pchisq(10/15, df = 2)


```

### 1.5 - Distribution de Student

1.  Soit $X\sim t_{10000}$ et $Z \sim N(0,1)$. Calculez le quantile à 95 % des deux distributions. Que remarquez-vous ?

2.  Soit $X\sim t_1$. Générez 1000 nombres aléatoires à partir de cette distribution et attribuez-les à la variable `x`. Calculez la moyenne de l'échantillon de x. Pouvez-vous expliquer le résultat ?

```{r Solution 1.5, eval=F}
#1
qt(0.95, df = 10000)
qnorm(0.95)

# both values are very close to each other. This is not surprising as for sufficient large degrees of freedom the t distribution can be approximated by the standard normal distribution.
#2
set.seed(123)
x <- rt(1000, df = 1)
#curve(dt(x, df = 2), xlim = c(-5, 5))
mean(x) #pour df = 1, student = cauchy pour qui l'espérance n'est pas définie

```

### 1.6 - Distribution de Fisher

1.  Soit $Y \sim F(10,4)$. Tracez la fonction quantile de la distribution donnée à l'aide de la fonction `curve()`.
2.  Soit $Y \sim F(4,5)$. Calculez $P(1<Y<10)$ en intégrant la PDF avec la fonction `integrate`.

```{r Solution 1.6, eval=F}
#1
curve(qf(x,df1 = 10, df2 = 4), 0, 10)
#2
integrate(df, lower = 1, upper = 10, df1 = 4, df2 = 5)$value
```

## 2. Statistiques avec R

### 2.1 - Biais

On considère l'estimateur alternatif suivant pour $\mu_Y$, la moyenne de $Y$ : $$\widetilde{Y}= \frac{1}{n-1}\sum_{i=1}^n Y_i$$

1.  Définissez une fonction `Y_tilde()` qui implémente l'estimateur ci-dessus.

2.  Tirez aléatoirement 5 observations au hasard à partir de la distribution $N(10,25)$ et calculez une estimation en utilisant `Y_tilde()`. Répétez cette procédure 10000 fois et stockez les résultats dans `est_biased` en utilisant la fonction `replicate`.

3.  Tracez un histogramme de `est_biased`. Ajoutez une ligne verticale rouge à $\mu=10$ en utilisant la fonction `abline()`.

4.  Tirez aléatoirement 1000 observations au hasard à partir de la distribution $N(10,25)$ et calculez une estimation de la moyenne en utilisant`Y_tilde()`. Répétez cette procédure 10000 fois et stockez les résultats dans `est_consistent.`

5.  Tracez un histogramme de `est_consistent`. Ajoutez une ligne verticale rouge à $\mu=10$ en utilisant la fonction `abline()`.

```{r Solution 2.1, eval=F}
set.seed(123)

#1
Y_tilde <- function(Y){ 1/(length(Y)-1)*sum(Y)}

#2
est_biased <- replicate(n = 10000, expr = Y_tilde(rnorm(5, 10, 5)))

#3 - à compiler ensemble
hist(est_biased) ; abline(v = 10, col = "red")

mean(est_biased) - 10

#4
est_consistent <- replicate(n = 10000, expr = Y_tilde(rnorm(1000, 10, 5)))

#5 - 
hist(est_consistent) ; abline(v = 10, col = "red")

mean(est_consistent) - 10

```

### 2.2 - Efficience d'un estimateur

Dans cet exercice, nous souhaitons illustrer le résultat selon lequel la moyenne de l'échantillon :

$$\widehat{\mu}_Y=\sum\limits_{i=1}^{n} a_i Y_i$$ avec le schéma de pondération égale $a_i=\frac{1}{n}$ pour $i=1,...,n$ est l'estimateur linéaire non biaisé meilleur (BLUE) de $\mu_Y$.

En tant qu'alternative, considérez l'estimateur :

$$\widetilde{\mu}_Y=\sum\limits_{i=1}^{n}b_iY_i$$

où $b_i$ donne aux premières $\frac{n}{2}$ observations un poids plus élevé de 3 que les deuxièmes $\frac{n}{2}$ observations (nous supposons que $n$ est pair pour simplifier).

%Le vecteur de poids $w$ a déjà été défini et est disponible dans votre environnement de travail.

1.  Définissez un vecteur de pondération pour une taille d'échantillon `n=100`. Il doit être normalisé.

2.  Vérifiez que $\tilde{\mu}_Y$ est un estimateur non biaisé de $\mu_Y$, la moyenne de $Y_i$.

3.  Implémentez l'estimateur alternatif de $\mu_Y$ en tant que fonction `mu_tilde()`.

4.  Tirez au hasard 100 observations à partir de la distribution $\mathcal{N}(5, 10)$ et calculez les estimations avec les deux estimateurs. Répétez cette procédure 10000 fois et stockez les résultats dans `est_bar` et `est_tilde`. Utilisez la fonction `replicate`.

5.  Calculez les variances de l'échantillon de `est_bar` et `est_tilde`. Que pouvez-vous dire sur les deux estimateurs?

```{r Solution 2.2, eval=F}
#1
n <- 100
w <- c(rep((1+0.5)/n, n/2), rep((1-0.5)/n, n/2))

#2
sum(w)

#3
mu_tilde <- function(Y){ sum(w*Y)}

#4
set.seed(123)
est_bar <- replicate(expr = mean(rnorm(100, 5, 10)), n = 10000)
est_tilde <- replicate(expr = mu_tilde(rnorm(100, 5, 10)), n = 10000)

#5
var(est_bar)
var(est_tilde)
```

### 2.3 - Test d'hypothèse

Considérez l'ensemble de données `wage1` du package `wooldridge`. La variable `wage` donne les gains horaires moyens des individus. Nous supposons que les gains horaires moyens `wage` dépassent 10 dollars par heure et souhaitons tester cette hypothèse à un niveau de signification de $\alpha=0,05$. Veuillez faire ce qui suit :

1.  Calculez la statistique de test manuellement et attribuez-la à `tstat`.

2.  Utilisez `tstat` pour accepter ou rejeter l'hypothèse nulle.

3.  Refaites-le en utilisant l'approximation normale.

4.  Calculez la valeur-p manuellement et attribuez-la à `pval` en utilisant l'approximation normale.

5.  Utilisez `pval` pour accepter ou rejeter l'hypothèse nulle.

6.  Effectuez le test d'hypothèse des questions précédentes en utilisant la fonction `t.test()`.

7.  Extrayez la statistique t et la valeur-p de la liste créée par `t.test()`. Attribuez-les aux variables `tstat` et `pvalue`.

8.  Vérifiez que l'utilisation de l'approximation normale ici est également valide en calculant la différence entre les deux valeurs-p.

```{r Solution 2.3, eval=F}
library(wooldridge)
data(wage1)
hist(wage1$wage)

#1
tstat <- (mean(wage1$wage)-10)/(sd(wage1$wage)/sqrt(length(wage1$wage)))

#2
tstat > qt(0.95, length(wage1$wage), lower.tail = FALSE)
#tstat < qt(0.05, length(wage1$wage))

?qt
#3
tstat > qt(0.95, df =  length(wage1$wage))

#4
pval <- 1-pt(tstat)
  
#5
pval < 0.05

#6
t.test(wage1$wage, alternative = "greater", mu = 10)

#7
tstat  <- t.test(wage1$wage, alternative = "greater", mu = 10)$statistic
pvalue <- t.test(wage1$wage, alternative = "greater", mu = 10)$p.value

#8
pvalue - pval


#data(ports)
#portpirie
```

### 2.4 - Test d'hypothèse : valeur-p

On considère les données CO2 (`data(CO2)`).

1.  Tester s'il existe une différence significative dans l'absorption entre les plantes traitées et les plantes non traitées à un niveau de signification de $\alpha$=0,05.

2.  Obtenez l'intervalle de confiance.

```{r Solution 2.4, eval=F}
#1
data(CO2)
plot(uptake ~ Treatment, data=CO2)

uptake_nonchilled <- CO2 %>% filter(Treatment=='nonchilled') %>% select(uptake)
uptake_chilled <- CO2 %>% filter(Treatment=='chilled') %>% select(uptake)

t.test(uptake_nonchilled, uptake_chilled)

t.test(uptake ~ Treatment, paired = TRUE, data=CO2)

#2
test <- t.test(uptake_nonchilled, uptake_chilled)
test$conf.int
```

### 2.5 - Corrélation

Charger la librarie `corrgram` et le jeu de données `auto`.

1.  Calculez la corrélation simple (linéaire) entre le prix de la voiture (`Price`) et son économie de carburant `MPG` (mesurée en miles par gallon, ou mpg).

2.  Utilisez la fonction `cor.test` pour vérifier si le coefficient obtenu est statistiquement significatif au niveau de 5 %.

3.  La corrélation simple suppose une relation linéaire entre les variables, mais il peut être utile de relâcher cette hypothèse. Calculez le coefficient de corrélation de Spearman pour les mêmes variables et trouvez sa signification statistique.

4.  En R, il est possible de calculer la corrélation pour toutes les paires de variables numériques dans un dataframe en une seule fois. Cependant, cela nécessite d'exclure d'abord les variables non numériques. Créez un nouveau dataframe, `auto_num`, qui ne contient que les colonnes avec des valeurs numériques du dataframe `auto`. Vous pouvez le faire en utilisant la fonction `filter`.

5.  Utilisez la fonction `cor` pour créer une matrice de coefficients de corrélation pour les variables du dataframe `auto_num`.

6.  La fonction standard `cor.test` ne fonctionne pas avec des dataframes. Cependant, la signification statistique des coefficients de corrélation pour un dataframe peut être vérifiée à l'aide de la fonction `rcorr` du package `Hmisc`. Transformez le dataframe `auto_num` en une matrice (`auto_mat`) et utilisez-le pour vérifier la signification des coefficients de corrélation avec la fonction `rcorr`.

7.  Utilisez la fonction `corrgram` du package `corrgram` pour créer un correlogramme par défaut afin de visualiser les corrélations entre les variables du dataframe `auto`.

8.  Créez un autre correlogramme qui (1) ne comprend que le panneau inférieur, (2) utilise des diagrammes en camembert pour représenter les coefficients de corrélation et (3) ordonne les variables selon l'ordre par défaut.

9.  Créez un nouveau dataframe, `auto_subset`, en sous-échantillonnant le dataframe `auto` pour inclure uniquement les variables `Price`, `MPG`, `Hroom` et `Rseat`. Utilisez le nouveau dataframe pour créer un correlogramme qui (1) affiche les coefficients de corrélation dans le panneau inférieur et (2) montre des diagrammes de dispersion (points) dans le panneau supérieur.

10. Utilisez la fonction `correlations` du package `ggm` pour créer une matrice de corrélation avec à la fois des coefficients de corrélation complets et partiels pour le dataframe `auto_subset`. Trouvez la corrélation partielle entre le prix de la voiture et son économie de carburant.

```{r Solution 2.5}

library(corrgram)
data(auto)

#1
cor(auto$Price, auto$MPG)

#2
cor.test(auto$Price, auto$MPG)

#3
cor.test(auto$Price, auto$MPG, method = 'spearman')

#4
auto_num <- Filter(is.numeric, auto)

#5
cor(auto_num)

#6 
library(Hmisc)
auto_mat <- as.matrix(auto_num)
rcorr(auto_mat)

#7
library(corrgram)
corrgram(auto)

#8
corrgram(auto, lower.panel = panel.pie, upper.panel = NULL, order = TRUE)

#9
auto_subset <- auto[, c('Price', 'MPG', 'Rseat', 'Hroom')]
corrgram(auto_subset, lower.panel = panel.cor, upper.panel = panel.pts)

#10
library(ggm)
correlations(auto_subset)

library(PerformanceAnalytics) 
chart.Correlation(auto_subset, histogram=TRUE, pch=19)





#https://www.r-exercises.com/2017/04/08/correlation-and-correlogram-exercises/

```
